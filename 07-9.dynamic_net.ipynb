{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Control Flow + Weight Sharing\n",
    "--------------------------------------\n",
    "\n",
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange\n",
    "model: a fully-connected ReLU network that on each forward pass randomly chooses\n",
    "a number between 1 and 4 and has that many hidden layers, reusing the same\n",
    "weights multiple times to compute the innermost hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 648.9775390625\n",
      "1 646.5050659179688\n",
      "2 642.1493530273438\n",
      "3 641.8135986328125\n",
      "4 685.8380126953125\n",
      "5 642.6522216796875\n",
      "6 584.0333251953125\n",
      "7 621.5007934570312\n",
      "8 455.608154296875\n",
      "9 608.1010131835938\n",
      "10 632.3406372070312\n",
      "11 616.1444091796875\n",
      "12 286.30694580078125\n",
      "13 630.7894897460938\n",
      "14 610.2770385742188\n",
      "15 606.1801147460938\n",
      "16 192.44374084472656\n",
      "17 548.6043090820312\n",
      "18 624.430419921875\n",
      "19 128.59329223632812\n",
      "20 618.9412231445312\n",
      "21 615.141357421875\n",
      "22 469.7901306152344\n",
      "23 444.9983215332031\n",
      "24 528.701904296875\n",
      "25 508.823974609375\n",
      "26 98.26380920410156\n",
      "27 556.087646484375\n",
      "28 297.55560302734375\n",
      "29 402.8298034667969\n",
      "30 103.24909973144531\n",
      "31 222.23342895507812\n",
      "32 317.0555419921875\n",
      "33 179.3186798095703\n",
      "34 156.77008056640625\n",
      "35 348.9098205566406\n",
      "36 112.85706329345703\n",
      "37 100.86849212646484\n",
      "38 76.3909683227539\n",
      "39 52.423030853271484\n",
      "40 110.68841552734375\n",
      "41 26.18639373779297\n",
      "42 251.68824768066406\n",
      "43 79.24877166748047\n",
      "44 180.97434997558594\n",
      "45 144.20106506347656\n",
      "46 64.11666107177734\n",
      "47 82.76520538330078\n",
      "48 66.82251739501953\n",
      "49 58.85480499267578\n",
      "50 64.66484832763672\n",
      "51 191.25189208984375\n",
      "52 122.52545928955078\n",
      "53 87.65965270996094\n",
      "54 217.461181640625\n",
      "55 27.180150985717773\n",
      "56 145.8426055908203\n",
      "57 138.36422729492188\n",
      "58 121.21624755859375\n",
      "59 54.28692626953125\n",
      "60 91.1296615600586\n",
      "61 234.7136688232422\n",
      "62 56.571571350097656\n",
      "63 81.29415893554688\n",
      "64 63.12725830078125\n",
      "65 49.884307861328125\n",
      "66 128.21604919433594\n",
      "67 129.73373413085938\n",
      "68 109.60214233398438\n",
      "69 54.52413558959961\n",
      "70 40.32679748535156\n",
      "71 34.33185958862305\n",
      "72 33.50032424926758\n",
      "73 59.3743896484375\n",
      "74 138.69793701171875\n",
      "75 22.753015518188477\n",
      "76 73.09320068359375\n",
      "77 64.57786560058594\n",
      "78 19.1218318939209\n",
      "79 43.637359619140625\n",
      "80 15.492708206176758\n",
      "81 14.064385414123535\n",
      "82 12.875131607055664\n",
      "83 47.6169548034668\n",
      "84 12.316262245178223\n",
      "85 25.795291900634766\n",
      "86 65.95413208007812\n",
      "87 26.696504592895508\n",
      "88 37.86943435668945\n",
      "89 45.1378173828125\n",
      "90 28.316438674926758\n",
      "91 26.50058937072754\n",
      "92 10.39927864074707\n",
      "93 10.715388298034668\n",
      "94 19.64857292175293\n",
      "95 10.725574493408203\n",
      "96 17.789342880249023\n",
      "97 5.667351722717285\n",
      "98 30.07431411743164\n",
      "99 16.328643798828125\n",
      "100 23.462289810180664\n",
      "101 12.361534118652344\n",
      "102 15.34566593170166\n",
      "103 17.651348114013672\n",
      "104 6.957489490509033\n",
      "105 10.578339576721191\n",
      "106 6.409218788146973\n",
      "107 34.4920654296875\n",
      "108 4.727025508880615\n",
      "109 4.247016906738281\n",
      "110 28.92848777770996\n",
      "111 12.476473808288574\n",
      "112 14.350969314575195\n",
      "113 2.7456533908843994\n",
      "114 10.91561222076416\n",
      "115 3.3593692779541016\n",
      "116 9.16690444946289\n",
      "117 36.18571472167969\n",
      "118 11.6221923828125\n",
      "119 12.758157730102539\n",
      "120 12.908827781677246\n",
      "121 78.15864562988281\n",
      "122 20.790035247802734\n",
      "123 8.859711647033691\n",
      "124 60.30841827392578\n",
      "125 18.3410701751709\n",
      "126 48.66096115112305\n",
      "127 49.65592956542969\n",
      "128 17.487703323364258\n",
      "129 40.116233825683594\n",
      "130 23.055267333984375\n",
      "131 85.57706451416016\n",
      "132 45.38372039794922\n",
      "133 14.366320610046387\n",
      "134 23.578453063964844\n",
      "135 33.35676574707031\n",
      "136 37.185428619384766\n",
      "137 14.792082786560059\n",
      "138 7.064555644989014\n",
      "139 69.22196197509766\n",
      "140 12.11778736114502\n",
      "141 21.008480072021484\n",
      "142 29.910186767578125\n",
      "143 33.71869659423828\n",
      "144 22.675079345703125\n",
      "145 10.107951164245605\n",
      "146 22.12192153930664\n",
      "147 11.96458625793457\n",
      "148 97.78397369384766\n",
      "149 6.319124698638916\n",
      "150 32.44894027709961\n",
      "151 22.688518524169922\n",
      "152 19.289859771728516\n",
      "153 19.29167938232422\n",
      "154 12.361062049865723\n",
      "155 9.632977485656738\n",
      "156 5.849842071533203\n",
      "157 48.39349365234375\n",
      "158 24.77444076538086\n",
      "159 31.13036346435547\n",
      "160 25.45709800720215\n",
      "161 13.344772338867188\n",
      "162 27.8204345703125\n",
      "163 10.362438201904297\n",
      "164 10.429652214050293\n",
      "165 10.659712791442871\n",
      "166 11.642184257507324\n",
      "167 8.028162956237793\n",
      "168 22.396146774291992\n",
      "169 20.075170516967773\n",
      "170 10.159571647644043\n",
      "171 10.124712944030762\n",
      "172 11.29326343536377\n",
      "173 5.894205093383789\n",
      "174 3.581998825073242\n",
      "175 3.748772144317627\n",
      "176 8.770217895507812\n",
      "177 7.494778156280518\n",
      "178 3.597165584564209\n",
      "179 3.863057851791382\n",
      "180 6.209025859832764\n",
      "181 3.537093162536621\n",
      "182 9.406315803527832\n",
      "183 4.730820178985596\n",
      "184 4.7424211502075195\n",
      "185 11.599898338317871\n",
      "186 3.8699328899383545\n",
      "187 4.869608402252197\n",
      "188 4.692812442779541\n",
      "189 6.6141252517700195\n",
      "190 3.231642961502075\n",
      "191 7.364253997802734\n",
      "192 4.410050392150879\n",
      "193 7.880736827850342\n",
      "194 2.1524510383605957\n",
      "195 5.370965957641602\n",
      "196 8.301863670349121\n",
      "197 3.6374340057373047\n",
      "198 1.8340387344360352\n",
      "199 8.649194717407227\n",
      "200 3.1072378158569336\n",
      "201 1.7874627113342285\n",
      "202 4.405350208282471\n",
      "203 13.531304359436035\n",
      "204 1.0082173347473145\n",
      "205 2.568986177444458\n",
      "206 5.66848611831665\n",
      "207 1.047695517539978\n",
      "208 2.3920321464538574\n",
      "209 1.0980608463287354\n",
      "210 0.9887852668762207\n",
      "211 3.765465497970581\n",
      "212 3.1891398429870605\n",
      "213 1.6121954917907715\n",
      "214 2.9240565299987793\n",
      "215 2.2243382930755615\n",
      "216 1.3605014085769653\n",
      "217 3.4329075813293457\n",
      "218 3.094067335128784\n",
      "219 2.7444088459014893\n",
      "220 2.167135000228882\n",
      "221 2.5324325561523438\n",
      "222 1.2408803701400757\n",
      "223 1.903896689414978\n",
      "224 2.0278406143188477\n",
      "225 2.692117214202881\n",
      "226 3.0751984119415283\n",
      "227 2.6880483627319336\n",
      "228 1.6184213161468506\n",
      "229 1.3162790536880493\n",
      "230 0.7326194643974304\n",
      "231 10.46973991394043\n",
      "232 0.3852538466453552\n",
      "233 0.3624018132686615\n",
      "234 3.4587974548339844\n",
      "235 2.4501984119415283\n",
      "236 1.5844447612762451\n",
      "237 1.7345068454742432\n",
      "238 1.6446470022201538\n",
      "239 1.5289491415023804\n",
      "240 2.4930009841918945\n",
      "241 2.5112948417663574\n",
      "242 1.6901323795318604\n",
      "243 1.9167742729187012\n",
      "244 4.040738105773926\n",
      "245 0.4638778865337372\n",
      "246 1.8087170124053955\n",
      "247 3.75923752784729\n",
      "248 1.380105972290039\n",
      "249 0.43667227029800415\n",
      "250 2.0808939933776855\n",
      "251 1.5657073259353638\n",
      "252 1.311766266822815\n",
      "253 1.066938877105713\n",
      "254 0.956892728805542\n",
      "255 2.38647198677063\n",
      "256 0.5731354355812073\n",
      "257 0.6831538677215576\n",
      "258 0.6510382890701294\n",
      "259 2.169889450073242\n",
      "260 1.0954982042312622\n",
      "261 0.31258639693260193\n",
      "262 1.4832096099853516\n",
      "263 1.788620114326477\n",
      "264 1.8040473461151123\n",
      "265 0.8725326657295227\n",
      "266 1.282939076423645\n",
      "267 0.5321709513664246\n",
      "268 0.8857749104499817\n",
      "269 1.9630122184753418\n",
      "270 0.9740397334098816\n",
      "271 1.1144603490829468\n",
      "272 2.016602039337158\n",
      "273 2.3983352184295654\n",
      "274 0.8757175803184509\n",
      "275 2.010807514190674\n",
      "276 1.5069934129714966\n",
      "277 1.9716472625732422\n",
      "278 1.2896888256072998\n",
      "279 1.4976190328598022\n",
      "280 1.2450573444366455\n",
      "281 0.832370400428772\n",
      "282 1.247401237487793\n",
      "283 1.2413424253463745\n",
      "284 0.365589439868927\n",
      "285 0.8843543529510498\n",
      "286 0.9264144897460938\n",
      "287 0.9825630187988281\n",
      "288 0.8993686437606812\n",
      "289 0.474269837141037\n",
      "290 0.39603498578071594\n",
      "291 0.8935878276824951\n",
      "292 0.8871740698814392\n",
      "293 0.7651886940002441\n",
      "294 0.6419053077697754\n",
      "295 0.24283158779144287\n",
      "296 0.23655511438846588\n",
      "297 0.9299063086509705\n",
      "298 1.090073823928833\n",
      "299 0.9406664967536926\n",
      "300 1.2272626161575317\n",
      "301 1.1933658123016357\n",
      "302 1.031294345855713\n",
      "303 0.8650439977645874\n",
      "304 0.9305018782615662\n",
      "305 0.9423288702964783\n",
      "306 1.3361499309539795\n",
      "307 0.9772022366523743\n",
      "308 1.139219880104065\n",
      "309 1.2016701698303223\n",
      "310 0.40484127402305603\n",
      "311 0.38669881224632263\n",
      "312 0.5240391492843628\n",
      "313 0.2613708972930908\n",
      "314 0.18984803557395935\n",
      "315 0.8248353004455566\n",
      "316 0.643710196018219\n",
      "317 1.0187073945999146\n",
      "318 0.32723328471183777\n",
      "319 0.7675741910934448\n",
      "320 0.8313354253768921\n",
      "321 0.5071068406105042\n",
      "322 0.2310049682855606\n",
      "323 0.8674007058143616\n",
      "324 0.17518916726112366\n",
      "325 0.9884320497512817\n",
      "326 0.1286579817533493\n",
      "327 0.8516075611114502\n",
      "328 0.609276533126831\n",
      "329 0.11680005490779877\n",
      "330 0.6236681938171387\n",
      "331 0.1352059245109558\n",
      "332 0.6097248792648315\n",
      "333 0.7726151943206787\n",
      "334 0.33682358264923096\n",
      "335 0.8958939909934998\n",
      "336 0.3353370130062103\n",
      "337 0.7799447774887085\n",
      "338 0.08760914951562881\n",
      "339 1.0087615251541138\n",
      "340 0.5299715399742126\n",
      "341 0.9847679734230042\n",
      "342 0.880717396736145\n",
      "343 0.3883204758167267\n",
      "344 0.653434693813324\n",
      "345 0.8770044445991516\n",
      "346 0.3703996539115906\n",
      "347 0.3582985997200012\n",
      "348 0.4475211799144745\n",
      "349 0.5602548122406006\n",
      "350 0.7870347499847412\n",
      "351 0.16366910934448242\n",
      "352 0.15236467123031616\n",
      "353 0.1390717476606369\n",
      "354 0.5285606980323792\n",
      "355 0.5123066902160645\n",
      "356 0.07536405324935913\n",
      "357 0.06685579568147659\n",
      "358 0.06622093170881271\n",
      "359 0.41721227765083313\n",
      "360 0.07021234184503555\n",
      "361 0.06464363634586334\n",
      "362 0.8602423667907715\n",
      "363 0.74248206615448\n",
      "364 0.6331112384796143\n",
      "365 0.8017812371253967\n",
      "366 0.1431393027305603\n",
      "367 0.574632465839386\n",
      "368 0.7190389633178711\n",
      "369 0.49876201152801514\n",
      "370 0.4005778431892395\n",
      "371 0.6392207145690918\n",
      "372 0.5381782054901123\n",
      "373 0.17026540637016296\n",
      "374 0.6220150589942932\n",
      "375 0.5218548774719238\n",
      "376 0.5794667601585388\n",
      "377 0.6474798321723938\n",
      "378 0.32676273584365845\n",
      "379 0.5115289688110352\n",
      "380 0.13576607406139374\n",
      "381 0.411018967628479\n",
      "382 0.0842975303530693\n",
      "383 0.06472164392471313\n",
      "384 0.053181037306785583\n",
      "385 0.48137345910072327\n",
      "386 0.04377070441842079\n",
      "387 0.7102500796318054\n",
      "388 0.6702196598052979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 0.5718395113945007\n",
      "390 0.45080092549324036\n",
      "391 0.5746116638183594\n",
      "392 0.8309420943260193\n",
      "393 0.6727114319801331\n",
      "394 0.6056891083717346\n",
      "395 0.505732536315918\n",
      "396 0.1628689020872116\n",
      "397 0.12365368008613586\n",
      "398 0.08635041862726212\n",
      "399 0.5267108678817749\n",
      "400 0.4192533791065216\n",
      "401 0.4209129810333252\n",
      "402 0.41378602385520935\n",
      "403 0.19856002926826477\n",
      "404 0.16643434762954712\n",
      "405 0.11080358922481537\n",
      "406 0.26556992530822754\n",
      "407 0.9801313877105713\n",
      "408 0.5869809985160828\n",
      "409 0.2858535349369049\n",
      "410 1.042236566543579\n",
      "411 0.8219985365867615\n",
      "412 0.6575505137443542\n",
      "413 0.36951741576194763\n",
      "414 0.9422004222869873\n",
      "415 0.8377964496612549\n",
      "416 0.4281536042690277\n",
      "417 0.3331311047077179\n",
      "418 0.5153644680976868\n",
      "419 0.49676772952079773\n",
      "420 0.6329869627952576\n",
      "421 1.096946120262146\n",
      "422 0.17794817686080933\n",
      "423 0.23617829382419586\n",
      "424 1.1639161109924316\n",
      "425 0.13709668815135956\n",
      "426 0.47403398156166077\n",
      "427 0.43766409158706665\n",
      "428 0.8926413059234619\n",
      "429 0.08124659210443497\n",
      "430 0.08675819635391235\n",
      "431 0.8785804510116577\n",
      "432 0.6421918869018555\n",
      "433 0.44723641872406006\n",
      "434 0.49263182282447815\n",
      "435 0.558799147605896\n",
      "436 0.5478885173797607\n",
      "437 0.4221736788749695\n",
      "438 0.5386027097702026\n",
      "439 0.5228736400604248\n",
      "440 0.07154528051614761\n",
      "441 0.9898622632026672\n",
      "442 0.08691904693841934\n",
      "443 0.3399892747402191\n",
      "444 0.3063216507434845\n",
      "445 0.3029903173446655\n",
      "446 0.9345118999481201\n",
      "447 0.6232357621192932\n",
      "448 0.5097590088844299\n",
      "449 0.7620934844017029\n",
      "450 1.0803359746932983\n",
      "451 0.9471368193626404\n",
      "452 0.27799463272094727\n",
      "453 0.09666094928979874\n",
      "454 1.5957162380218506\n",
      "455 0.0758623257279396\n",
      "456 2.704960346221924\n",
      "457 0.23399771749973297\n",
      "458 0.3933400511741638\n",
      "459 3.4447834491729736\n",
      "460 2.4254863262176514\n",
      "461 0.38115623593330383\n",
      "462 0.9244781732559204\n",
      "463 2.5203464031219482\n",
      "464 1.9236105680465698\n",
      "465 1.0363749265670776\n",
      "466 0.3977862000465393\n",
      "467 2.662238597869873\n",
      "468 0.714724063873291\n",
      "469 0.2474922239780426\n",
      "470 0.28589290380477905\n",
      "471 0.16873584687709808\n",
      "472 0.15145069360733032\n",
      "473 0.43799492716789246\n",
      "474 1.7359684705734253\n",
      "475 0.602812647819519\n",
      "476 1.0488430261611938\n",
      "477 0.8666279315948486\n",
      "478 1.013690710067749\n",
      "479 0.6967852115631104\n",
      "480 1.0627549886703491\n",
      "481 1.3005485534667969\n",
      "482 0.42826300859451294\n",
      "483 0.43754953145980835\n",
      "484 0.32870131731033325\n",
      "485 0.206791490316391\n",
      "486 0.141046404838562\n",
      "487 0.1506190299987793\n",
      "488 1.248705506324768\n",
      "489 0.17089347541332245\n",
      "490 0.5893430113792419\n",
      "491 0.699781060218811\n",
      "492 0.6591936349868774\n",
      "493 0.5148999691009521\n",
      "494 0.3785278797149658\n",
      "495 0.4661923944950104\n",
      "496 0.38478463888168335\n",
      "497 0.6920077800750732\n",
      "498 0.44725143909454346\n",
      "499 0.5563709139823914\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
