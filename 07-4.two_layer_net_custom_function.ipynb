{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Defining New autograd Functions\n",
    "----------------------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation computes the forward pass using operations on PyTorch\n",
    "Variables, and uses PyTorch autograd to compute gradients.\n",
    "\n",
    "In this implementation we implement our own custom autograd function to perform\n",
    "the ReLU function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29054064.0\n",
      "1 25657364.0\n",
      "2 28104228.0\n",
      "3 32269688.0\n",
      "4 33563164.0\n",
      "5 28637716.0\n",
      "6 19101244.0\n",
      "7 10342804.0\n",
      "8 5067596.0\n",
      "9 2585022.75\n",
      "10 1510459.25\n",
      "11 1028231.125\n",
      "12 783344.75\n",
      "13 637096.25\n",
      "14 536253.875\n",
      "15 459728.625\n",
      "16 398431.75\n",
      "17 347762.15625\n",
      "18 305214.9375\n",
      "19 269118.28125\n",
      "20 238287.5625\n",
      "21 211781.78125\n",
      "22 188851.25\n",
      "23 168933.53125\n",
      "24 151549.03125\n",
      "25 136308.125\n",
      "26 122902.390625\n",
      "27 111073.078125\n",
      "28 100600.671875\n",
      "29 91324.1328125\n",
      "30 83070.046875\n",
      "31 75704.6640625\n",
      "32 69111.0\n",
      "33 63191.6796875\n",
      "34 57862.84375\n",
      "35 53058.58984375\n",
      "36 48718.3671875\n",
      "37 44790.9609375\n",
      "38 41234.26953125\n",
      "39 38004.0546875\n",
      "40 35066.375\n",
      "41 32389.73046875\n",
      "42 29948.15625\n",
      "43 27717.8515625\n",
      "44 25678.353515625\n",
      "45 23811.451171875\n",
      "46 22099.123046875\n",
      "47 20527.67578125\n",
      "48 19082.919921875\n",
      "49 17754.0703125\n",
      "50 16530.421875\n",
      "51 15403.0087890625\n",
      "52 14363.220703125\n",
      "53 13403.572265625\n",
      "54 12516.25390625\n",
      "55 11694.740234375\n",
      "56 10934.021484375\n",
      "57 10229.349609375\n",
      "58 9575.646484375\n",
      "59 8968.7734375\n",
      "60 8405.2099609375\n",
      "61 7881.32177734375\n",
      "62 7393.86474609375\n",
      "63 6940.07861328125\n",
      "64 6517.01513671875\n",
      "65 6122.6044921875\n",
      "66 5755.0888671875\n",
      "67 5412.2119140625\n",
      "68 5092.1318359375\n",
      "69 4792.9970703125\n",
      "70 4513.3515625\n",
      "71 4251.84521484375\n",
      "72 4007.03369140625\n",
      "73 3777.83642578125\n",
      "74 3563.09814453125\n",
      "75 3361.80517578125\n",
      "76 3172.99658203125\n",
      "77 2995.86962890625\n",
      "78 2829.669921875\n",
      "79 2673.55224609375\n",
      "80 2526.82861328125\n",
      "81 2388.9580078125\n",
      "82 2259.2841796875\n",
      "83 2137.2890625\n",
      "84 2022.568603515625\n",
      "85 1914.5662841796875\n",
      "86 1812.7919921875\n",
      "87 1716.89599609375\n",
      "88 1626.5478515625\n",
      "89 1541.351806640625\n",
      "90 1461.017822265625\n",
      "91 1385.2490234375\n",
      "92 1313.6971435546875\n",
      "93 1246.1572265625\n",
      "94 1182.376708984375\n",
      "95 1122.1312255859375\n",
      "96 1065.1763916015625\n",
      "97 1011.36376953125\n",
      "98 960.4930419921875\n",
      "99 912.354736328125\n",
      "100 866.835693359375\n",
      "101 823.7657470703125\n",
      "102 782.9830322265625\n",
      "103 744.3648681640625\n",
      "104 707.7921142578125\n",
      "105 673.1571044921875\n",
      "106 640.3233642578125\n",
      "107 609.2017211914062\n",
      "108 579.7200927734375\n",
      "109 551.744384765625\n",
      "110 525.2019653320312\n",
      "111 500.03326416015625\n",
      "112 476.1510925292969\n",
      "113 453.48602294921875\n",
      "114 432.0722961425781\n",
      "115 411.7804870605469\n",
      "116 392.4917907714844\n",
      "117 374.167236328125\n",
      "118 356.7569274902344\n",
      "119 340.21270751953125\n",
      "120 324.4804382324219\n",
      "121 309.52130126953125\n",
      "122 295.2989501953125\n",
      "123 281.7635192871094\n",
      "124 268.8856506347656\n",
      "125 256.6369323730469\n",
      "126 244.98196411132812\n",
      "127 233.87872314453125\n",
      "128 223.3102264404297\n",
      "129 213.25210571289062\n",
      "130 203.6678009033203\n",
      "131 194.53628540039062\n",
      "132 185.8363037109375\n",
      "133 177.5521240234375\n",
      "134 169.65487670898438\n",
      "135 162.1249542236328\n",
      "136 154.94683837890625\n",
      "137 148.1099395751953\n",
      "138 141.58453369140625\n",
      "139 135.35882568359375\n",
      "140 129.4208221435547\n",
      "141 123.76077270507812\n",
      "142 118.35839080810547\n",
      "143 113.20173645019531\n",
      "144 108.28245544433594\n",
      "145 103.58856964111328\n",
      "146 99.10368347167969\n",
      "147 94.8212890625\n",
      "148 90.7340087890625\n",
      "149 86.83242797851562\n",
      "150 83.10396575927734\n",
      "151 79.54280853271484\n",
      "152 76.14132690429688\n",
      "153 72.89273071289062\n",
      "154 69.78732299804688\n",
      "155 66.8199462890625\n",
      "156 63.98285675048828\n",
      "157 61.275150299072266\n",
      "158 58.682456970214844\n",
      "159 56.20501708984375\n",
      "160 53.835411071777344\n",
      "161 51.57151794433594\n",
      "162 49.40589904785156\n",
      "163 47.333683013916016\n",
      "164 45.351654052734375\n",
      "165 43.45771789550781\n",
      "166 41.64440155029297\n",
      "167 39.90909957885742\n",
      "168 38.24863815307617\n",
      "169 36.660362243652344\n",
      "170 35.14115524291992\n",
      "171 33.685874938964844\n",
      "172 32.29313659667969\n",
      "173 30.959537506103516\n",
      "174 29.684181213378906\n",
      "175 28.46246337890625\n",
      "176 27.292469024658203\n",
      "177 26.172237396240234\n",
      "178 25.09943962097168\n",
      "179 24.072858810424805\n",
      "180 23.088550567626953\n",
      "181 22.145490646362305\n",
      "182 21.24258041381836\n",
      "183 20.378314971923828\n",
      "184 19.54949951171875\n",
      "185 18.7552433013916\n",
      "186 17.994884490966797\n",
      "187 17.26586151123047\n",
      "188 16.567771911621094\n",
      "189 15.898275375366211\n",
      "190 15.25668716430664\n",
      "191 14.641409873962402\n",
      "192 14.052244186401367\n",
      "193 13.486786842346191\n",
      "194 12.945202827453613\n",
      "195 12.42540454864502\n",
      "196 11.927789688110352\n",
      "197 11.450517654418945\n",
      "198 10.992559432983398\n",
      "199 10.553446769714355\n",
      "200 10.131990432739258\n",
      "201 9.728071212768555\n",
      "202 9.341464042663574\n",
      "203 8.9696044921875\n",
      "204 8.61311149597168\n",
      "205 8.27115249633789\n",
      "206 7.943151950836182\n",
      "207 7.62861442565918\n",
      "208 7.326672077178955\n",
      "209 7.0370283126831055\n",
      "210 6.759132385253906\n",
      "211 6.492573261260986\n",
      "212 6.236785888671875\n",
      "213 5.991120338439941\n",
      "214 5.755350112915039\n",
      "215 5.529130458831787\n",
      "216 5.311962127685547\n",
      "217 5.10355281829834\n",
      "218 4.903806686401367\n",
      "219 4.711623668670654\n",
      "220 4.527222633361816\n",
      "221 4.350330352783203\n",
      "222 4.180483818054199\n",
      "223 4.017374038696289\n",
      "224 3.860745429992676\n",
      "225 3.7103638648986816\n",
      "226 3.565983295440674\n",
      "227 3.4273037910461426\n",
      "228 3.2940802574157715\n",
      "229 3.1662111282348633\n",
      "230 3.043403387069702\n",
      "231 2.9255118370056152\n",
      "232 2.812217950820923\n",
      "233 2.7034294605255127\n",
      "234 2.598783016204834\n",
      "235 2.498485803604126\n",
      "236 2.4018728733062744\n",
      "237 2.309410572052002\n",
      "238 2.2203590869903564\n",
      "239 2.134868621826172\n",
      "240 2.0526347160339355\n",
      "241 1.9737391471862793\n",
      "242 1.897796630859375\n",
      "243 1.8249938488006592\n",
      "244 1.7549959421157837\n",
      "245 1.687673807144165\n",
      "246 1.62301766872406\n",
      "247 1.5608896017074585\n",
      "248 1.5012004375457764\n",
      "249 1.4437081813812256\n",
      "250 1.3885350227355957\n",
      "251 1.3356115818023682\n",
      "252 1.2846437692642212\n",
      "253 1.2356730699539185\n",
      "254 1.188656210899353\n",
      "255 1.1433202028274536\n",
      "256 1.0998530387878418\n",
      "257 1.0579488277435303\n",
      "258 1.0178048610687256\n",
      "259 0.9791585206985474\n",
      "260 0.9420512318611145\n",
      "261 0.906307578086853\n",
      "262 0.8719688057899475\n",
      "263 0.8389963507652283\n",
      "264 0.8071521520614624\n",
      "265 0.7766560316085815\n",
      "266 0.7473292946815491\n",
      "267 0.7191332578659058\n",
      "268 0.6919330954551697\n",
      "269 0.6658278107643127\n",
      "270 0.6406502723693848\n",
      "271 0.6165434122085571\n",
      "272 0.5933327078819275\n",
      "273 0.5710311532020569\n",
      "274 0.5495762228965759\n",
      "275 0.5288535356521606\n",
      "276 0.5090032815933228\n",
      "277 0.48994603753089905\n",
      "278 0.471540629863739\n",
      "279 0.45390084385871887\n",
      "280 0.4368445873260498\n",
      "281 0.42049360275268555\n",
      "282 0.4047570824623108\n",
      "283 0.38962486386299133\n",
      "284 0.3750624656677246\n",
      "285 0.361047625541687\n",
      "286 0.3475382924079895\n",
      "287 0.33458811044692993\n",
      "288 0.3221011161804199\n",
      "289 0.31007981300354004\n",
      "290 0.2985163927078247\n",
      "291 0.28743964433670044\n",
      "292 0.27672475576400757\n",
      "293 0.2664218842983246\n",
      "294 0.2565135955810547\n",
      "295 0.24698123335838318\n",
      "296 0.23779067397117615\n",
      "297 0.228999063372612\n",
      "298 0.2205086052417755\n",
      "299 0.21232974529266357\n",
      "300 0.20446640253067017\n",
      "301 0.19687780737876892\n",
      "302 0.18958044052124023\n",
      "303 0.18257680535316467\n",
      "304 0.17577984929084778\n",
      "305 0.1693214774131775\n",
      "306 0.16305692493915558\n",
      "307 0.15703760087490082\n",
      "308 0.1512642800807953\n",
      "309 0.1456749439239502\n",
      "310 0.1402936428785324\n",
      "311 0.13511162996292114\n",
      "312 0.13014042377471924\n",
      "313 0.1253722459077835\n",
      "314 0.12072944641113281\n",
      "315 0.11630233377218246\n",
      "316 0.11201774328947067\n",
      "317 0.10791034996509552\n",
      "318 0.10395582020282745\n",
      "319 0.10014637559652328\n",
      "320 0.09645423293113708\n",
      "321 0.09293419122695923\n",
      "322 0.08954870700836182\n",
      "323 0.08624181151390076\n",
      "324 0.08311330527067184\n",
      "325 0.08005351573228836\n",
      "326 0.07714100182056427\n",
      "327 0.07431426644325256\n",
      "328 0.07159813493490219\n",
      "329 0.06898705661296844\n",
      "330 0.06646718084812164\n",
      "331 0.06403304636478424\n",
      "332 0.06171692907810211\n",
      "333 0.05947945639491081\n",
      "334 0.05730453506112099\n",
      "335 0.055222488939762115\n",
      "336 0.05320637673139572\n",
      "337 0.051291484385728836\n",
      "338 0.04943086951971054\n",
      "339 0.047645773738622665\n",
      "340 0.045927468687295914\n",
      "341 0.044254884123802185\n",
      "342 0.042645104229450226\n",
      "343 0.041101522743701935\n",
      "344 0.039612095803022385\n",
      "345 0.03819922357797623\n",
      "346 0.03681398928165436\n",
      "347 0.03548091650009155\n",
      "348 0.03420510143041611\n",
      "349 0.032964643090963364\n",
      "350 0.03178318217396736\n",
      "351 0.030647480860352516\n",
      "352 0.029537364840507507\n",
      "353 0.028479447588324547\n",
      "354 0.02746526151895523\n",
      "355 0.02647201530635357\n",
      "356 0.02552274987101555\n",
      "357 0.024613259360194206\n",
      "358 0.023737942799925804\n",
      "359 0.02288389764726162\n",
      "360 0.022074919193983078\n",
      "361 0.021285299211740494\n",
      "362 0.020527858287096024\n",
      "363 0.019805699586868286\n",
      "364 0.019099324941635132\n",
      "365 0.018420541658997536\n",
      "366 0.01777321845293045\n",
      "367 0.017146341502666473\n",
      "368 0.016541270539164543\n",
      "369 0.015958651900291443\n",
      "370 0.015399642288684845\n",
      "371 0.014853643253445625\n",
      "372 0.014334749430418015\n",
      "373 0.013832607306540012\n",
      "374 0.013351727277040482\n",
      "375 0.012882038950920105\n",
      "376 0.012428502552211285\n",
      "377 0.011998207308351994\n",
      "378 0.011574357748031616\n",
      "379 0.011183535680174828\n",
      "380 0.010787837207317352\n",
      "381 0.010416590608656406\n",
      "382 0.010057937353849411\n",
      "383 0.009713434614241123\n",
      "384 0.009377211332321167\n",
      "385 0.009059757925570011\n",
      "386 0.008744156919419765\n",
      "387 0.008443895727396011\n",
      "388 0.008158762007951736\n",
      "389 0.007875536568462849\n",
      "390 0.007607888430356979\n",
      "391 0.007353710941970348\n",
      "392 0.0071066697128117085\n",
      "393 0.006867139600217342\n",
      "394 0.006634852383285761\n",
      "395 0.0064127203077077866\n",
      "396 0.006201440934091806\n",
      "397 0.00599304074421525\n",
      "398 0.005795430392026901\n",
      "399 0.005599051248282194\n",
      "400 0.005412560421973467\n",
      "401 0.005233273841440678\n",
      "402 0.005061931908130646\n",
      "403 0.004898860119283199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 0.004738704767078161\n",
      "405 0.004582607187330723\n",
      "406 0.004436916671693325\n",
      "407 0.004291645251214504\n",
      "408 0.004153021145612001\n",
      "409 0.004018784034997225\n",
      "410 0.0038907628040760756\n",
      "411 0.003769516246393323\n",
      "412 0.0036483623553067446\n",
      "413 0.003534065093845129\n",
      "414 0.0034203235991299152\n",
      "415 0.0033133020624518394\n",
      "416 0.0032083282712846994\n",
      "417 0.0031095552258193493\n",
      "418 0.0030122706666588783\n",
      "419 0.0029170173220336437\n",
      "420 0.0028239742387086153\n",
      "421 0.0027423426508903503\n",
      "422 0.002656154567375779\n",
      "423 0.0025746093597263098\n",
      "424 0.0024968008510768414\n",
      "425 0.002421833109110594\n",
      "426 0.0023483342956751585\n",
      "427 0.0022770653013139963\n",
      "428 0.0022092743311077356\n",
      "429 0.002143465681001544\n",
      "430 0.002080705715343356\n",
      "431 0.0020195599645376205\n",
      "432 0.0019602628890424967\n",
      "433 0.0019039383623749018\n",
      "434 0.0018479425925761461\n",
      "435 0.001794559066183865\n",
      "436 0.001741899410262704\n",
      "437 0.0016920154448598623\n",
      "438 0.0016422360204160213\n",
      "439 0.0015963874757289886\n",
      "440 0.001549141830764711\n",
      "441 0.0015050973743200302\n",
      "442 0.0014651136007159948\n",
      "443 0.001423834590241313\n",
      "444 0.0013852152042090893\n",
      "445 0.0013454536674544215\n",
      "446 0.001308324164710939\n",
      "447 0.0012725491542369127\n",
      "448 0.0012380543630570173\n",
      "449 0.0012025204487144947\n",
      "450 0.0011709312675520778\n",
      "451 0.0011393185704946518\n",
      "452 0.0011084553552791476\n",
      "453 0.001078515313565731\n",
      "454 0.0010494187008589506\n",
      "455 0.0010214687790721655\n",
      "456 0.0009943702025339007\n",
      "457 0.0009680113289505243\n",
      "458 0.0009435942047275603\n",
      "459 0.0009180897613987327\n",
      "460 0.0008940252009779215\n",
      "461 0.0008720300393179059\n",
      "462 0.0008498699171468616\n",
      "463 0.0008279435569420457\n",
      "464 0.0008066623704507947\n",
      "465 0.0007865042425692081\n",
      "466 0.0007671268540434539\n",
      "467 0.0007482494693249464\n",
      "468 0.0007301117875613272\n",
      "469 0.0007121270173229277\n",
      "470 0.0006955107091926038\n",
      "471 0.0006778840906918049\n",
      "472 0.0006612993311136961\n",
      "473 0.0006454166141338646\n",
      "474 0.000629439833573997\n",
      "475 0.0006138294702395797\n",
      "476 0.0005997979897074401\n",
      "477 0.0005851284367963672\n",
      "478 0.0005710390396416187\n",
      "479 0.0005577260162681341\n",
      "480 0.0005452482146210968\n",
      "481 0.0005332361906766891\n",
      "482 0.0005212241667322814\n",
      "483 0.0005082673160359263\n",
      "484 0.0004969590227119625\n",
      "485 0.0004856525920331478\n",
      "486 0.0004745089972857386\n",
      "487 0.00046376953832805157\n",
      "488 0.00045351131120696664\n",
      "489 0.00044232694199308753\n",
      "490 0.0004323911853134632\n",
      "491 0.0004233506915625185\n",
      "492 0.00041419631452299654\n",
      "493 0.0004051359137520194\n",
      "494 0.00039639213355258107\n",
      "495 0.0003880856093019247\n",
      "496 0.0003787916502915323\n",
      "497 0.0003703878610394895\n",
      "498 0.0003630708088167012\n",
      "499 0.00035511457826942205\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'relu'.\n",
    "    relu = MyReLU.apply\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
