{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Tensors and autograd\n",
    "-------------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer and no biases, trained to\n",
    "predict y from x by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation computes the forward pass using operations on PyTorch\n",
    "Tensors, and uses PyTorch autograd to compute gradients.\n",
    "\n",
    "\n",
    "A PyTorch Tensor represents a node in a computational graph. If ``x`` is a\n",
    "Tensor that has ``x.requires_grad=True`` then ``x.grad`` is another Tensor\n",
    "holding the gradient of ``x`` with respect to some scalar value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36648040.0\n",
      "1 31270364.0\n",
      "2 28291568.0\n",
      "3 23690084.0\n",
      "4 17462892.0\n",
      "5 11329606.0\n",
      "6 6811175.0\n",
      "7 4049316.5\n",
      "8 2517866.0\n",
      "9 1685369.75\n",
      "10 1216834.5\n",
      "11 934351.6875\n",
      "12 749346.75\n",
      "13 618704.4375\n",
      "14 520777.1875\n",
      "15 443974.4375\n",
      "16 382033.09375\n",
      "17 331037.875\n",
      "18 288493.25\n",
      "19 252631.140625\n",
      "20 222124.3125\n",
      "21 196008.609375\n",
      "22 173514.0625\n",
      "23 154025.078125\n",
      "24 137121.15625\n",
      "25 122399.734375\n",
      "26 109516.6171875\n",
      "27 98204.6875\n",
      "28 88241.0859375\n",
      "29 79438.9453125\n",
      "30 71650.9453125\n",
      "31 64740.890625\n",
      "32 58590.296875\n",
      "33 53107.3203125\n",
      "34 48203.07421875\n",
      "35 43810.359375\n",
      "36 39867.0859375\n",
      "37 36321.234375\n",
      "38 33129.45703125\n",
      "39 30251.53515625\n",
      "40 27651.212890625\n",
      "41 25299.625\n",
      "42 23170.48828125\n",
      "43 21239.447265625\n",
      "44 19486.140625\n",
      "45 17892.6875\n",
      "46 16442.896484375\n",
      "47 15129.53125\n",
      "48 13931.080078125\n",
      "49 12836.708984375\n",
      "50 11836.71875\n",
      "51 10921.63671875\n",
      "52 10084.16796875\n",
      "53 9316.7373046875\n",
      "54 8612.8466796875\n",
      "55 7966.734375\n",
      "56 7373.3291015625\n",
      "57 6828.0546875\n",
      "58 6326.4384765625\n",
      "59 5864.708984375\n",
      "60 5439.453125\n",
      "61 5047.50390625\n",
      "62 4686.08251953125\n",
      "63 4352.521484375\n",
      "64 4044.7265625\n",
      "65 3760.320556640625\n",
      "66 3497.49169921875\n",
      "67 3254.30712890625\n",
      "68 3029.27197265625\n",
      "69 2821.015380859375\n",
      "70 2628.09375\n",
      "71 2449.3427734375\n",
      "72 2283.560546875\n",
      "73 2129.769287109375\n",
      "74 1987.034912109375\n",
      "75 1854.5255126953125\n",
      "76 1731.4384765625\n",
      "77 1617.0762939453125\n",
      "78 1510.7440185546875\n",
      "79 1411.70263671875\n",
      "80 1319.57177734375\n",
      "81 1233.818115234375\n",
      "82 1154.002685546875\n",
      "83 1079.65185546875\n",
      "84 1010.3709716796875\n",
      "85 945.797119140625\n",
      "86 885.58154296875\n",
      "87 829.4498291015625\n",
      "88 777.067138671875\n",
      "89 728.17138671875\n",
      "90 682.51025390625\n",
      "91 639.8685302734375\n",
      "92 600.03515625\n",
      "93 562.8118896484375\n",
      "94 528.02783203125\n",
      "95 495.4947204589844\n",
      "96 465.0599365234375\n",
      "97 436.59307861328125\n",
      "98 409.9627685546875\n",
      "99 385.0325927734375\n",
      "100 361.6837158203125\n",
      "101 339.827392578125\n",
      "102 319.34954833984375\n",
      "103 300.1585693359375\n",
      "104 282.1709289550781\n",
      "105 265.30999755859375\n",
      "106 249.49783325195312\n",
      "107 234.67503356933594\n",
      "108 220.76876831054688\n",
      "109 207.71728515625\n",
      "110 195.4666748046875\n",
      "111 183.9730987548828\n",
      "112 173.18365478515625\n",
      "113 163.0513916015625\n",
      "114 153.53274536132812\n",
      "115 144.59176635742188\n",
      "116 136.19012451171875\n",
      "117 128.2962646484375\n",
      "118 120.87451171875\n",
      "119 113.89881134033203\n",
      "120 107.34061431884766\n",
      "121 101.17581176757812\n",
      "122 95.37284088134766\n",
      "123 89.91490173339844\n",
      "124 84.77983093261719\n",
      "125 79.94709777832031\n",
      "126 75.400390625\n",
      "127 71.12026977539062\n",
      "128 67.09033203125\n",
      "129 63.29415512084961\n",
      "130 59.72160339355469\n",
      "131 56.356571197509766\n",
      "132 53.1864128112793\n",
      "133 50.19964599609375\n",
      "134 47.38627243041992\n",
      "135 44.73429870605469\n",
      "136 42.23457336425781\n",
      "137 39.878482818603516\n",
      "138 37.658119201660156\n",
      "139 35.56456756591797\n",
      "140 33.58940124511719\n",
      "141 31.7271785736084\n",
      "142 29.97166633605957\n",
      "143 28.315181732177734\n",
      "144 26.75261688232422\n",
      "145 25.278274536132812\n",
      "146 23.887306213378906\n",
      "147 22.574542999267578\n",
      "148 21.336090087890625\n",
      "149 20.167104721069336\n",
      "150 19.06332778930664\n",
      "151 18.020946502685547\n",
      "152 17.037464141845703\n",
      "153 16.10860824584961\n",
      "154 15.231782913208008\n",
      "155 14.403467178344727\n",
      "156 13.621217727661133\n",
      "157 12.882185935974121\n",
      "158 12.18435001373291\n",
      "159 11.524856567382812\n",
      "160 10.901567459106445\n",
      "161 10.3128023147583\n",
      "162 9.756775856018066\n",
      "163 9.231304168701172\n",
      "164 8.7345609664917\n",
      "165 8.2644624710083\n",
      "166 7.820713043212891\n",
      "167 7.401194095611572\n",
      "168 7.004550933837891\n",
      "169 6.629433631896973\n",
      "170 6.274967193603516\n",
      "171 5.939401626586914\n",
      "172 5.622254848480225\n",
      "173 5.322587966918945\n",
      "174 5.03903341293335\n",
      "175 4.770852565765381\n",
      "176 4.517183303833008\n",
      "177 4.276890754699707\n",
      "178 4.049862861633301\n",
      "179 3.8349862098693848\n",
      "180 3.6314945220947266\n",
      "181 3.439122438430786\n",
      "182 3.257213592529297\n",
      "183 3.0848538875579834\n",
      "184 2.9218106269836426\n",
      "185 2.7676496505737305\n",
      "186 2.6215600967407227\n",
      "187 2.4832968711853027\n",
      "188 2.3525466918945312\n",
      "189 2.228703737258911\n",
      "190 2.111556053161621\n",
      "191 2.0004451274871826\n",
      "192 1.8955464363098145\n",
      "193 1.7960920333862305\n",
      "194 1.7018643617630005\n",
      "195 1.6126642227172852\n",
      "196 1.5283069610595703\n",
      "197 1.4483482837677002\n",
      "198 1.3727076053619385\n",
      "199 1.3010551929473877\n",
      "200 1.2330811023712158\n",
      "201 1.168766975402832\n",
      "202 1.1079318523406982\n",
      "203 1.0501775741577148\n",
      "204 0.9954545497894287\n",
      "205 0.9436243176460266\n",
      "206 0.8945735096931458\n",
      "207 0.8480895757675171\n",
      "208 0.8041749000549316\n",
      "209 0.7623803019523621\n",
      "210 0.7227820754051208\n",
      "211 0.6853457689285278\n",
      "212 0.6498746275901794\n",
      "213 0.6162221431732178\n",
      "214 0.5843889713287354\n",
      "215 0.5540502667427063\n",
      "216 0.5254921317100525\n",
      "217 0.49829864501953125\n",
      "218 0.4725855588912964\n",
      "219 0.4481838047504425\n",
      "220 0.4251018166542053\n",
      "221 0.4032115936279297\n",
      "222 0.38243311643600464\n",
      "223 0.3627169132232666\n",
      "224 0.3440719544887543\n",
      "225 0.3263615667819977\n",
      "226 0.30956798791885376\n",
      "227 0.2936740815639496\n",
      "228 0.2786155939102173\n",
      "229 0.26433008909225464\n",
      "230 0.2508060336112976\n",
      "231 0.23788577318191528\n",
      "232 0.22569024562835693\n",
      "233 0.2141074538230896\n",
      "234 0.20316198468208313\n",
      "235 0.19275617599487305\n",
      "236 0.1828857660293579\n",
      "237 0.17355668544769287\n",
      "238 0.16467368602752686\n",
      "239 0.15626290440559387\n",
      "240 0.1482897400856018\n",
      "241 0.1407071053981781\n",
      "242 0.13351841270923615\n",
      "243 0.12668593227863312\n",
      "244 0.12024737894535065\n",
      "245 0.11413854360580444\n",
      "246 0.10830023884773254\n",
      "247 0.10279541462659836\n",
      "248 0.09755535423755646\n",
      "249 0.09260768443346024\n",
      "250 0.08787500858306885\n",
      "251 0.08341754972934723\n",
      "252 0.07917218655347824\n",
      "253 0.07515593618154526\n",
      "254 0.07134900242090225\n",
      "255 0.06770540773868561\n",
      "256 0.06427768617868423\n",
      "257 0.06103839352726936\n",
      "258 0.057940833270549774\n",
      "259 0.054985951632261276\n",
      "260 0.052208587527275085\n",
      "261 0.049566611647605896\n",
      "262 0.047051623463630676\n",
      "263 0.04467644542455673\n",
      "264 0.04243222624063492\n",
      "265 0.040283527225255966\n",
      "266 0.03823826089501381\n",
      "267 0.036322221159935\n",
      "268 0.03448677808046341\n",
      "269 0.03276676684617996\n",
      "270 0.03110586106777191\n",
      "271 0.029529616236686707\n",
      "272 0.028066355735063553\n",
      "273 0.026631716638803482\n",
      "274 0.02528918720781803\n",
      "275 0.024031609296798706\n",
      "276 0.022834569215774536\n",
      "277 0.021688498556613922\n",
      "278 0.020595120266079903\n",
      "279 0.01957448571920395\n",
      "280 0.018597636371850967\n",
      "281 0.01767411082983017\n",
      "282 0.016795381903648376\n",
      "283 0.015962442383170128\n",
      "284 0.015171114355325699\n",
      "285 0.014416630379855633\n",
      "286 0.013701500371098518\n",
      "287 0.013016042299568653\n",
      "288 0.012378865852952003\n",
      "289 0.011762609705328941\n",
      "290 0.011183131486177444\n",
      "291 0.010628223419189453\n",
      "292 0.010110298171639442\n",
      "293 0.009611254557967186\n",
      "294 0.00913952011615038\n",
      "295 0.008686866611242294\n",
      "296 0.008266297169029713\n",
      "297 0.00786629319190979\n",
      "298 0.007487194612622261\n",
      "299 0.007124707102775574\n",
      "300 0.006783772725611925\n",
      "301 0.006461011711508036\n",
      "302 0.00614950992166996\n",
      "303 0.005852132104337215\n",
      "304 0.005572243593633175\n",
      "305 0.00530989607796073\n",
      "306 0.005058100447058678\n",
      "307 0.004815856926143169\n",
      "308 0.004590225405991077\n",
      "309 0.004372670780867338\n",
      "310 0.004171015229076147\n",
      "311 0.003975452855229378\n",
      "312 0.0037906370125710964\n",
      "313 0.0036150573287159204\n",
      "314 0.0034490188118070364\n",
      "315 0.0032919663935899734\n",
      "316 0.0031411556992679834\n",
      "317 0.0029998882673680782\n",
      "318 0.0028661778196692467\n",
      "319 0.002737642265856266\n",
      "320 0.002611177507787943\n",
      "321 0.0024961326271295547\n",
      "322 0.0023871171288192272\n",
      "323 0.002282643225044012\n",
      "324 0.0021822908893227577\n",
      "325 0.0020881511736661196\n",
      "326 0.001996788661926985\n",
      "327 0.0019117480842396617\n",
      "328 0.0018292306922376156\n",
      "329 0.0017524564173072577\n",
      "330 0.0016783042810857296\n",
      "331 0.001608219463378191\n",
      "332 0.0015388077590614557\n",
      "333 0.0014768458204343915\n",
      "334 0.001415852690115571\n",
      "335 0.0013578995130956173\n",
      "336 0.001301883952692151\n",
      "337 0.0012489682994782925\n",
      "338 0.001198374549858272\n",
      "339 0.0011525145964697003\n",
      "340 0.0011068470776081085\n",
      "341 0.0010633079800754786\n",
      "342 0.00102241151034832\n",
      "343 0.0009840618586167693\n",
      "344 0.0009457952110096812\n",
      "345 0.0009098586742766201\n",
      "346 0.0008751933928579092\n",
      "347 0.0008436926873400807\n",
      "348 0.0008116129320114851\n",
      "349 0.0007832288974896073\n",
      "350 0.0007554639014415443\n",
      "351 0.0007280494319275022\n",
      "352 0.0007015272276476026\n",
      "353 0.0006774698849767447\n",
      "354 0.0006542672053910792\n",
      "355 0.0006322722183540463\n",
      "356 0.0006116001168265939\n",
      "357 0.0005892058834433556\n",
      "358 0.0005702124326489866\n",
      "359 0.0005508845788426697\n",
      "360 0.0005334834568202496\n",
      "361 0.0005158924032002687\n",
      "362 0.0004994507180526853\n",
      "363 0.00048286456149071455\n",
      "364 0.00046724078129045665\n",
      "365 0.0004528251593001187\n",
      "366 0.0004385615175124258\n",
      "367 0.00042477942770347\n",
      "368 0.00041124364361166954\n",
      "369 0.0003989156393799931\n",
      "370 0.0003869309148285538\n",
      "371 0.00037572873407043517\n",
      "372 0.0003638584748841822\n",
      "373 0.00035273359389975667\n",
      "374 0.0003426477196626365\n",
      "375 0.0003327158046886325\n",
      "376 0.000322585750836879\n",
      "377 0.00031335430685430765\n",
      "378 0.00030411616899073124\n",
      "379 0.00029530859319493175\n",
      "380 0.00028700154507532716\n",
      "381 0.000278919207630679\n",
      "382 0.00027122636674903333\n",
      "383 0.0002641867031343281\n",
      "384 0.0002567038463894278\n",
      "385 0.00024982658214867115\n",
      "386 0.000243567003053613\n",
      "387 0.00023671209055464715\n",
      "388 0.00023081398103386164\n",
      "389 0.0002248218806926161\n",
      "390 0.00021900692081544548\n",
      "391 0.00021332025062292814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 0.00020756993035320193\n",
      "393 0.00020294445857871324\n",
      "394 0.00019733811495825648\n",
      "395 0.0001927552802953869\n",
      "396 0.00018786126747727394\n",
      "397 0.00018302342505194247\n",
      "398 0.0001785367203410715\n",
      "399 0.00017467838188167661\n",
      "400 0.00017058514640666544\n",
      "401 0.0001660620328038931\n",
      "402 0.0001617136731510982\n",
      "403 0.0001578264927957207\n",
      "404 0.00015442079165950418\n",
      "405 0.00015049260400701314\n",
      "406 0.00014696312427986413\n",
      "407 0.00014397682389244437\n",
      "408 0.00014077976811677217\n",
      "409 0.0001375796418869868\n",
      "410 0.00013483833754435182\n",
      "411 0.00013198294618632644\n",
      "412 0.00012876381515525281\n",
      "413 0.0001258822885574773\n",
      "414 0.0001230129855684936\n",
      "415 0.00012038624845445156\n",
      "416 0.00011794274905696511\n",
      "417 0.0001152399490820244\n",
      "418 0.00011270192771917209\n",
      "419 0.00011036627984140068\n",
      "420 0.00010818462033057585\n",
      "421 0.00010550846491241828\n",
      "422 0.00010388552618678659\n",
      "423 0.00010178507363889366\n",
      "424 9.97145107248798e-05\n",
      "425 9.770008182385936e-05\n",
      "426 9.56034054979682e-05\n",
      "427 9.372118074679747e-05\n",
      "428 9.227659757016227e-05\n",
      "429 9.040843724505976e-05\n",
      "430 8.884780982043594e-05\n",
      "431 8.702358172740787e-05\n",
      "432 8.551350038032979e-05\n",
      "433 8.364219684153795e-05\n",
      "434 8.23133741505444e-05\n",
      "435 8.069146133493632e-05\n",
      "436 7.931341679068282e-05\n",
      "437 7.818911399226636e-05\n",
      "438 7.67674355302006e-05\n",
      "439 7.470545824617147e-05\n",
      "440 7.351906970143318e-05\n",
      "441 7.229109178297222e-05\n",
      "442 7.123059185687453e-05\n",
      "443 6.975545693421736e-05\n",
      "444 6.847092299722135e-05\n",
      "445 6.745853170286864e-05\n",
      "446 6.617327744606882e-05\n",
      "447 6.534202839247882e-05\n",
      "448 6.430088251363486e-05\n",
      "449 6.293309706961736e-05\n",
      "450 6.193574517965317e-05\n",
      "451 6.092535477364436e-05\n",
      "452 6.00234889134299e-05\n",
      "453 5.903505007154308e-05\n",
      "454 5.79852239752654e-05\n",
      "455 5.710227196686901e-05\n",
      "456 5.622124081128277e-05\n",
      "457 5.5143533245427534e-05\n",
      "458 5.422956746770069e-05\n",
      "459 5.3422605560626835e-05\n",
      "460 5.270458495942876e-05\n",
      "461 5.191258969716728e-05\n",
      "462 5.099121335661039e-05\n",
      "463 5.017030343879014e-05\n",
      "464 4.953661482431926e-05\n",
      "465 4.88265031890478e-05\n",
      "466 4.8161717131733894e-05\n",
      "467 4.733054811367765e-05\n",
      "468 4.645272565539926e-05\n",
      "469 4.592878030962311e-05\n",
      "470 4.529539728537202e-05\n",
      "471 4.457718750927597e-05\n",
      "472 4.393005292513408e-05\n",
      "473 4.318345236242749e-05\n",
      "474 4.2744264646898955e-05\n",
      "475 4.208119207760319e-05\n",
      "476 4.1334700654260814e-05\n",
      "477 4.0789982449496165e-05\n",
      "478 4.027861723443493e-05\n",
      "479 3.988008393207565e-05\n",
      "480 3.916236892109737e-05\n",
      "481 3.8551257603103295e-05\n",
      "482 3.81328645744361e-05\n",
      "483 3.765684232348576e-05\n",
      "484 3.703905167640187e-05\n",
      "485 3.654901229310781e-05\n",
      "486 3.603199002100155e-05\n",
      "487 3.5439530620351434e-05\n",
      "488 3.518319135764614e-05\n",
      "489 3.458500577835366e-05\n",
      "490 3.431058576097712e-05\n",
      "491 3.3811818866524845e-05\n",
      "492 3.349583130329847e-05\n",
      "493 3.294970520073548e-05\n",
      "494 3.2455893233418465e-05\n",
      "495 3.20365943480283e-05\n",
      "496 3.175587335135788e-05\n",
      "497 3.144341098959558e-05\n",
      "498 3.1015380955068395e-05\n",
      "499 3.068320074817166e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Tensors during the backward pass.\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Create random Tensors for weights.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the a scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Tensors holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    # An alternative way is to operate on weight.data and weight.grad.data.\n",
    "    # Recall that tensor.data gives a tensor that shares the storage with\n",
    "    # tensor, but doesn't track history.\n",
    "    # You can also use torch.optim.SGD to achieve this.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
